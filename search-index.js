var searchIndex = new Map(JSON.parse('[\
["mistralrs",{"doc":"","t":"PPPPPFFPPFFKFFFFFGPFPKPPFGFGPGGPPPMNNNNONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNMNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNMMNNNNNNNNNNNNNNNNNNNNNMNNNNMNNNNNNNNNNNNNNNNNMMMNOMNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNMONOONNOOMNNNNNMOOOOOONOOMOOONNNNNNNNMOOONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNOOONNNNNNNNNNNNNNNNN","n":["CacheToken","Done","EnvVar","Error","Fixed","GemmaLoader","GemmaSpecificConfig","Ids","Literal","LlamaLoader","LlamaSpecificConfig","Loader","MistralLoader","MistralRs","MistralSpecificConfig","MixtralLoader","MixtralSpecificConfig","ModelKind","Normal","Ordering","Path","Pipeline","QuantizedGGML","QuantizedGGUF","Request","Response","SamplingParams","SchedulerMethod","Seqs","StopTokens","TokenSource","XLoraGGML","XLoraGGUF","XLoraNormal","_setup_model","_setup_model","_setup_model","_setup_model","_setup_model","adapters","apply_chat_template","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","cache","clone","clone","clone","clone","clone","clone","clone","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deserialize","device","download_model","download_model","download_model","download_model","download_model","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","eos_tok","fmt","fmt","fmt","fmt","forward","from","from","from","from","from","from","from","from","from","from","from","from","from","from","from","from","from","get_chat_template","get_max_seq_len","get_non_granular_state","get_sender","gqa","has_no_kv_cache","init","init","init","init","init","init","init","init","init","init","init","init","init","init","init","init","init","into","into","into","into","into","into","into","into","into","into","into","into","into","into","into","into","into","is_xlora","layers","load_model","logits_bias","max_len","maybe_log_request","maybe_log_response","messages","n_choices","name","new","new","new","new","new","num_hidden_layers","presence_penalty","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_penalty","reset_non_granular_state","response","return_logprobs","sample","sampling_params","stop_toks","temperature","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","tokenize_prompt","tokenizer","top_k","top_n_logprobs","top_p","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","use_flash_attn","use_flash_attn","use_flash_attn","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip"],"q":[[0,"mistralrs"],[323,"mistralrs_core::pipeline"],[324,"candle_core::dtype"],[325,"core::option"],[326,"candle_core::device"],[327,"std::sync::mutex"],[328,"alloc::boxed"],[329,"anyhow"],[330,"core::result"],[331,"alloc::string"],[332,"indexmap::map"],[333,"alloc::vec"],[334,"mistralrs_core::models"],[335,"serde::de"],[336,"core::fmt"],[337,"core::fmt"],[338,"core::cell"],[339,"alloc::rc"],[340,"candle_core::tensor"],[341,"mistralrs_core::pipeline"],[342,"std::sync::mpsc"],[343,"alloc::sync"],[344,"mistralrs_core::response"],[345,"candle_sampling::logits_processor"],[346,"tokenizers::tokenizer"],[347,"core::any"]],"d":["","","","","","","","","","","","Encapsulate downloading and setting up the model. The …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","","","","","","","","","","","","","","","","","","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","If <code>revision</code> is None, then it defaults to <code>main</code>. If <code>dtype</code> is …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""],"i":[30,52,30,52,48,0,0,25,30,0,0,0,0,0,0,0,0,0,47,0,30,0,47,47,0,0,0,0,25,0,0,47,47,47,1,11,12,13,14,20,6,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,6,20,21,22,23,24,25,26,20,21,22,23,24,25,26,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,20,6,1,11,12,13,14,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,6,20,34,25,26,6,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,6,6,6,42,22,6,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,6,20,1,26,26,42,42,34,26,6,11,12,13,14,42,6,26,21,22,23,24,26,6,34,34,6,34,26,26,20,21,22,23,24,25,26,6,6,26,26,26,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26,22,23,24,20,11,12,13,14,30,47,34,52,48,42,21,22,23,24,25,26],"f":"``````````````````````````````````{{bd{h{f}}j}{{Ad{{A`{{n{l}}}}Ab}}}}{{Afd{h{f}}j}{{Ad{{A`{{n{l}}}}Ab}}}}{{Ahd{h{f}}j}{{Ad{{A`{{n{l}}}}Ab}}}}{{Ajd{h{f}}j}{{Ad{{A`{{n{l}}}}Ab}}}}{{Ald{h{f}}j}{{Ad{{A`{{n{l}}}}Ab}}}}`{{l{Bb{{B`{AnAn}}}}Bd}{{Ad{AnAb}}}}{ce{}{}}000000000000000000000000000000000{lBf}{BhBh}{BjBj}{BlBl}{BnBn}{C`C`}{CbCb}{CdCd}{{ce}Cf{}{}}000000{Chc{}}000000000000000000000000000000000{c{{Ad{Bh}}}Cj}{lj}{{b{h{An}}Cl}{{Ad{{A`{d}}Ab}}}}{{Af{h{An}}Cl}{{Ad{{A`{d}}Ab}}}}{{Ah{h{An}}Cl}{{Ad{{A`{d}}Ab}}}}{{Aj{h{An}}Cl}{{Ad{{A`{d}}Ab}}}}{{Al{h{An}}Cl}{{Ad{{A`{d}}Ab}}}}{ChCf}0000000000000000{lCn}{{BhD`}{{Ad{CfDb}}}}{{DdD`}{{Ad{CfDb}}}}{{CbD`}{{Ad{CfDb}}}}{{CdD`}{{Ad{CfDb}}}}{{l{A`{{Dl{{Dj{{Dh{Df}}}}}}}}Bd}Dn}{cc{}}0000000000000000{lE`}{lCh}{l{{h{Eb}}}}{Ed{{Ef{Dd}}}}`{lBd}{{}Ch}0000000000000000{ce{}{}}00000000000000002`{{b{h{An}}Cl{h{f}}j}{{Ad{{A`{{n{l}}}}Ab}}}}``{{{Eh{Ed}}An}Cf}{{{Eh{Ed}}Ej}Cf}``{lEl}{{AnBj{h{An}}{h{An}}{h{An}}En{h{Bh}}Bd{h{An}}{h{An}}{h{Ch}}}Af}{{AnBl{h{An}}{h{An}}{h{An}}En{h{Bh}}Bd{h{An}}{h{An}}{h{Ch}}}Ah}{{AnBn{h{An}}{h{An}}{h{An}}En{h{Bh}}Bd{h{An}}{h{An}}{h{Ch}}}Aj}{{AnC`{h{An}}{h{An}}{h{An}}En{h{Bh}}Bd{h{An}}{h{An}}{h{Ch}}}Al}{{{A`{{n{l}}}}F`{h{An}}BdBd}{{Eh{Ed}}}}>``````{lCf}``{{lDn{Dj{{Dh{Df}}}}}{{Ad{FbAb}}}}```;;;;;;;{{lEl}{{Ad{{Bb{Cn}}Ab}}}}{lFd}```{c{{Ad{e}}}{}{}}000000000000000000000000000000000{cFf{}}0000000000000000```?????????????????","c":[],"p":[[10,"Loader",0],[10,"ModelPaths",323],[6,"DType",324],[6,"Option",325],[6,"Device",326],[10,"Pipeline",0],[5,"Mutex",327],[5,"Box",328],[5,"Error",329],[6,"Result",330],[5,"GemmaLoader",0],[5,"LlamaLoader",0],[5,"MistralLoader",0],[5,"MixtralLoader",0],[5,"String",331],[5,"IndexMap",332],[5,"Vec",333],[1,"bool"],[5,"Cache",334],[5,"Ordering",0],[5,"GemmaSpecificConfig",0],[5,"LlamaSpecificConfig",0],[5,"MistralSpecificConfig",0],[5,"MixtralSpecificConfig",0],[6,"StopTokens",0],[5,"SamplingParams",0],[1,"unit"],[1,"usize"],[10,"Deserializer",335],[6,"TokenSource",0],[1,"u32"],[5,"Formatter",336],[5,"Error",336],[5,"Request",0],[5,"Sequence",337],[5,"RefCell",338],[5,"Rc",339],[1,"slice"],[5,"Tensor",340],[5,"ChatTemplate",323],[5,"NonGranularState",341],[5,"MistralRs",0],[5,"Sender",342],[5,"Arc",343],[5,"ChatCompletionResponse",344],[1,"str"],[6,"ModelKind",0],[6,"SchedulerMethod",0],[5,"Logprobs",345],[5,"Tokenizer",346],[5,"TypeId",347],[6,"Response",0]],"b":[]}],\
["mistralrs_core",{"doc":"","t":"PFFPPPPFFPPFFKFFFFFGPFPKPPFGFGPGGPPPMNNNNONNOOOONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNMONNNNNNNNNNNNNNNNNNOONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQQNQMMNNNNNNNNNNNNNNNNNNNNNNNMNNNNNNMNNNNNNNNNNNNNNNNNNNMMQMNOQQMONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNMONNOONNOOOMNNNNNMOOOOOOOONNOOMONNOOONNNNNNNNNNNMOOOONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNOOOONNNNNNNNNNNNNNNNNNN","n":["CacheToken","ChatCompletionResponse","ChatCompletionUsage","Done","EnvVar","Error","Fixed","GemmaLoader","GemmaSpecificConfig","Ids","Literal","LlamaLoader","LlamaSpecificConfig","Loader","MistralLoader","MistralRs","MistralSpecificConfig","MixtralLoader","MixtralSpecificConfig","ModelKind","Normal","Ordering","Path","Pipeline","QuantizedGGML","QuantizedGGUF","Request","Response","SamplingParams","SchedulerMethod","Seqs","StopTokens","TokenSource","XLoraGGML","XLoraGGUF","XLoraNormal","_setup_model","_setup_model","_setup_model","_setup_model","_setup_model","adapters","apply_chat_template","apply_chat_template","avg_compl_tok_per_sec","avg_prompt_tok_per_sec","avg_sample_tok_per_sec","avg_tok_per_sec","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","cache","choices","clone","clone","clone","clone","clone","clone","clone","clone","clone","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","completion_tokens","created","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut_refcell","deref_refcell","deserialize","deserialize_chat_template","device","download_model","download_model","download_model","download_model","download_model","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","eos_tok","fmt","fmt","fmt","fmt","fmt","fmt","forward","from","from","from","from","from","from","from","from","from","from","from","from","from","from","from","from","from","from","from","get_chat_template","get_max_seq_len","get_mut_arcmutex","get_non_granular_state","get_sender","gqa","handle_seq_error","handle_seq_error_stateaware","has_no_kv_cache","id","init","init","init","init","init","init","init","init","init","init","init","init","init","init","init","init","init","init","init","into","into","into","into","into","into","into","into","into","into","into","into","into","into","into","into","into","into","into","is_xlora","layers","load_model","load_model","logits_bias","max_len","maybe_log_request","maybe_log_response","messages","model","n_choices","name","new","new","new","new","new","num_hidden_layers","object","presence_penalty","prompt_tokens","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_penalty","reset_non_granular_state","reset_non_granular_state","response","return_logprobs","sample","sampling_params","serialize","serialize","stop_toks","system_fingerprint","temperature","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","tokenize_prompt","tokenize_prompt","tokenizer","top_k","top_n_logprobs","top_p","total_tokens","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","usage","use_flash_attn","use_flash_attn","use_flash_attn","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip"],"q":[[0,"mistralrs_core"],[383,"candle_core::dtype"],[384,"core::option"],[385,"candle_core::device"],[386,"std::sync::mutex"],[387,"alloc::boxed"],[388,"anyhow"],[389,"alloc::string"],[390,"indexmap::map"],[391,"alloc::vec"],[392,"core::result"],[393,"serde::de"],[394,"core::fmt"],[395,"core::fmt"],[396,"alloc::rc"],[397,"candle_core::tensor"],[398,"std::sync::mpsc"],[399,"alloc::sync"],[400,"candle_sampling::logits_processor"],[401,"serde::ser"],[402,"tokenizers::tokenizer"],[403,"core::any"]],"d":["","","","","","","","","","","","","","Encapsulate downloading and setting up the model. The …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","If <code>revision</code> is None, then it defaults to <code>main</code>. If <code>dtype</code> is …","If <code>revision</code> is None, then it defaults to <code>main</code>. If <code>dtype</code> is …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""],"i":[30,0,0,50,30,50,45,0,0,24,30,0,0,0,0,0,0,0,0,0,44,0,30,0,44,44,0,0,0,0,24,0,0,44,44,44,1,9,10,11,12,17,5,5,22,22,22,22,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,5,23,17,18,19,20,21,22,23,24,25,17,18,19,20,21,22,23,24,25,22,23,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,0,0,17,0,5,1,9,10,11,12,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,5,17,34,22,23,24,25,5,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,5,5,0,5,40,19,0,0,5,23,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,5,17,1,1,25,25,40,40,34,23,25,5,9,10,11,12,40,5,23,25,22,18,19,20,21,25,5,5,34,34,5,34,22,23,25,23,25,17,18,19,20,21,22,23,24,25,5,5,5,25,25,25,22,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25,23,19,20,21,17,9,10,11,12,30,44,34,50,45,40,18,19,20,21,22,23,24,25],"f":"``````````````````````````````````````````{{j{An{{Al{AjAj}}}}B`}{{A`{Aj}}}}0````{ce{}{}}0000000000000000000000000000000000000``{BbBb}{BdBd}{BfBf}{BhBh}{BjBj}{BlBl}{BnBn}{C`C`}{CbCb}{{ce}Cd{}{}}00000000``{Cfc{}}0000000000000000000000000000000000000``{c{{Ch{Bb}}}Cj}`{jh}{{b{f{Aj}}Cl}{{A`{{n{`}}}}}}{{Ab{f{Aj}}Cl}{{A`{{n{`}}}}}}{{Ad{f{Aj}}Cl}{{A`{{n{`}}}}}}{{Af{f{Aj}}Cl}{{A`{{n{`}}}}}}{{Ah{f{Aj}}Cl}{{A`{{n{`}}}}}}{CfCd}000000000000000000{jCn}{{BbD`}{{Ch{CdDb}}}}{{DdD`}Df}{{BlD`}Df}{{BnD`}Df}{{C`D`}Df}{{CbD`}Df}{{j{n{{Dl{{Dj{{Dh{`}}}}}}}}B`}Dn}{cc{}}000000000000000000`{jCf}`{j{{f{`}}}}{E`{{Eb{Dd}}}}```{jB`}`{{}Cf}000000000000000000{ce{}{}}0000000000000000002`{{b{f{Aj}}Cl{f{d}}h}{{A`{{n{{l{j}}}}}}}}0``{{{Ed{E`}}Aj}Cd}{{{Ed{E`}}Bn}Cd}```{jEf}{{AjBd{f{Aj}}{f{Aj}}{f{Aj}}Eh{f{Bb}}B`{f{Aj}}{f{Aj}}{f{Cf}}}Ab}{{AjBf{f{Aj}}{f{Aj}}{f{Aj}}Eh{f{Bb}}B`{f{Aj}}{f{Aj}}{f{Cf}}}Ad}{{AjBh{f{Aj}}{f{Aj}}{f{Aj}}Eh{f{Bb}}B`{f{Aj}}{f{Aj}}{f{Cf}}}Af}{{AjBj{f{Aj}}{f{Aj}}{f{Aj}}Eh{f{Bb}}B`{f{Aj}}{f{Aj}}{f{Cf}}}Ah}{{{n{{l{j}}}}Ej{f{Aj}}B`B`}{{Ed{E`}}}}>````````{jCd}0``{{jDn{Dj{{Dh{`}}}}}{{A`{El}}}}`{{Blc}ChEn}{{Bnc}ChEn}```========={{jEf}{{A`{{An{Cn}}}}}}0{jF`}````{c{{Ch{e}}}{}{}}0000000000000000000000000000000000000{cFb{}}000000000000000000````{ce{}{}}000000000000000000","c":[],"p":[[10,"Loader",0],[6,"DType",383],[6,"Option",384],[6,"Device",385],[10,"Pipeline",0],[5,"Mutex",386],[5,"Box",387],[8,"Result",388],[5,"GemmaLoader",0],[5,"LlamaLoader",0],[5,"MistralLoader",0],[5,"MixtralLoader",0],[5,"String",389],[5,"IndexMap",390],[5,"Vec",391],[1,"bool"],[5,"Ordering",0],[5,"GemmaSpecificConfig",0],[5,"LlamaSpecificConfig",0],[5,"MistralSpecificConfig",0],[5,"MixtralSpecificConfig",0],[5,"ChatCompletionUsage",0],[5,"ChatCompletionResponse",0],[6,"StopTokens",0],[5,"SamplingParams",0],[1,"unit"],[1,"usize"],[6,"Result",392],[10,"Deserializer",393],[6,"TokenSource",0],[1,"u32"],[5,"Formatter",394],[5,"Error",394],[5,"Request",0],[8,"Result",394],[5,"RefCell",395],[5,"Rc",396],[1,"slice"],[5,"Tensor",397],[5,"MistralRs",0],[5,"Sender",398],[5,"Arc",399],[1,"str"],[6,"ModelKind",0],[6,"SchedulerMethod",0],[5,"Logprobs",400],[10,"Serializer",401],[5,"Tokenizer",402],[5,"TypeId",403],[6,"Response",0]],"b":[]}],\
["mistralrs_lora",{"doc":"","t":"KFFFFOMNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNHNNNNNNNNOHHHMNNNNMNNNNNNNNNNNNNNNNNNNNMN","n":["LinearLayerLike","LoraConfig","LoraLinearConfig","Ordering","QLoraLinear","adapters","bias","bias","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","clone","clone","clone","clone_into","clone_into","clone_into","deref","deref","deref","deref","deref_mut","deref_mut","deref_mut","deref_mut","deserialize","deserialize","drop","drop","drop","drop","fmt","fmt","fmt","fmt","from","from","from","from","get_lora_cfg","init","init","init","init","into","into","into","into","layers","linear","linear_b","linear_no_bias","lora_forward","lora_forward","new","new","new","shape","shape","to_owned","to_owned","to_owned","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","vzip","vzip","vzip","vzip","weight","weight"],"q":[[0,"mistralrs_lora"],[85,"candle_core::tensor"],[86,"core::option"],[87,"core::result"],[88,"serde::de"],[89,"core::fmt"],[90,"core::fmt"],[91,"candle_nn::var_builder"],[92,"alloc::string"],[93,"alloc::vec"],[94,"alloc::sync"],[95,"candle_core::error"],[96,"candle_core::quantized"],[97,"candle_core::shape"],[98,"core::any"]],"d":["Any layer that is linear-like.","","Configuration for LoraLinear","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""],"i":[0,0,0,0,0,5,1,4,4,5,6,7,4,5,6,7,5,6,7,5,6,7,4,5,6,7,4,5,6,7,5,7,4,5,6,7,4,5,6,7,4,5,6,7,0,4,5,6,7,4,5,6,7,5,0,0,0,1,4,4,6,7,1,4,5,6,7,4,5,6,7,4,5,6,7,4,5,6,7,4,5,6,7,1,4],"f":"``````{b{{f{d}}}}{h{{f{d}}}}{ce{}{}}0000000{jj}{ll}{nn}{{ce}A`{}{}}00{Abc{}}0000000{c{{Ad{j}}}Af}{c{{Ad{n}}}Af}{AbA`}000{{hAh}Aj}{{jAh}Aj}{{lAh}Aj}{{nAh}Aj}{cc{}}000{All}{{}Ab}000????`{{AbAbAn{Bd{{Bb{B`n}}}}Abj}{{Bh{{Bf{b}}}}}}{{AbAbBjAn{Bd{{Bb{B`n}}}}Abj}{{Bh{{Bf{b}}}}}}1{{bddBl{f{Bl}}}{{Bh{d}}}}{{hddBl{f{Bl}}}{{Bh{d}}}}{{Bnl{C`{{Bb{B`n}}}}AnjB`Ab}{{Bh{h}}}}{{AbAb}l}{{AbBl{f{Cb}}{Cd{B`}}}n}{bCf}{hCf}{ce{}{}}00{c{{Ad{e}}}{}{}}0000000{cCh{}}0002222{bd}{hd}","c":[],"p":[[10,"LinearLayerLike",0],[5,"Tensor",85],[6,"Option",86],[5,"QLoraLinear",0],[5,"Ordering",0],[5,"LoraLinearConfig",0],[5,"LoraConfig",0],[1,"unit"],[1,"usize"],[6,"Result",87],[10,"Deserializer",88],[5,"Formatter",89],[8,"Result",89],[5,"QTensor",90],[8,"VarBuilder",91],[5,"String",92],[1,"tuple"],[5,"Vec",93],[5,"Arc",94],[8,"Result",95],[1,"bool"],[1,"f64"],[6,"QMatMul",90],[1,"slice"],[1,"f32"],[5,"HashSet",96],[5,"Shape",97],[5,"TypeId",98]],"b":[]}],\
["mistralrs_server",{"doc":"","t":"FPPPPPPPPGPPPPPPPPNNNNNNNNOHNNNNNNNNNNNNNNNHNNNNNNOHOOOCOOONNNNNNNNNNNNOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOFFPPPPGNNNNNNNNNNNNOHHNNNNNNNNNNNNNNNNNNNNNNNNNNNOOOOOOOOOONNNOONNNOOONNNNNNNNNNNN","n":["Args","Gemma","Llama","LlamaGGML","LlamaGGUF","Mistral","MistralGGUF","Mixtral","MixtralGGUF","ModelSelected","XLoraGemma","XLoraLlama","XLoraLlamaGGML","XLoraLlamaGGUF","XLoraMistral","XLoraMistralGGUF","XLoraMixtral","XLoraMixtralGGUF","augment_args","augment_args_for_update","augment_subcommands","augment_subcommands_for_update","borrow","borrow","borrow_mut","borrow_mut","chat_template","chatcompletions","command","command_for_update","deref","deref","deref_mut","deref_mut","drop","drop","fmt","from","from","from_arg_matches","from_arg_matches","from_arg_matches_mut","from_arg_matches_mut","get_router","group_id","has_subcommand","init","init","into","into","log","main","max_seqs","model","no_kv_cache","openai","port","serve_ip","truncate_sequence","try_from","try_from","try_into","try_into","type_id","type_id","update_from_arg_matches","update_from_arg_matches","update_from_arg_matches_mut","update_from_arg_matches_mut","vzip","vzip","gqa","gqa","model_id","model_id","model_id","model_id","model_id","model_id","model_id","model_id","order","order","order","order","order","order","order","order","quantized_filename","quantized_filename","quantized_filename","quantized_filename","quantized_filename","quantized_filename","quantized_filename","quantized_filename","quantized_model_id","quantized_model_id","quantized_model_id","quantized_model_id","quantized_model_id","quantized_model_id","quantized_model_id","quantized_model_id","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","repeat_last_n","tgt_non_granular_index","tgt_non_granular_index","tgt_non_granular_index","tgt_non_granular_index","tgt_non_granular_index","tgt_non_granular_index","tgt_non_granular_index","tgt_non_granular_index","tok_model_id","tok_model_id","tok_model_id","tok_model_id","tok_model_id","tok_model_id","tok_model_id","tok_model_id","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","tokenizer_json","xlora_model_id","xlora_model_id","xlora_model_id","xlora_model_id","xlora_model_id","xlora_model_id","xlora_model_id","xlora_model_id","ChatCompletionRequest","Message","Multi","MultiId","Single","SingleId","StopTokens","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","clone","clone","clone","clone_into","clone_into","clone_into","content","default_1usize","default_false","deref","deref","deref","deref_mut","deref_mut","deref_mut","deserialize","deserialize","deserialize","drop","drop","drop","fmt","fmt","fmt","from","from","from","from_ref","from_ref","from_ref","init","init","init","into","into","into","logit_bias","logprobs","max_tokens","messages","model","n_choices","name","presence_penalty","repetition_penalty","role","serialize","serialize","serialize","stop_seqs","temperature","to_owned","to_owned","to_owned","top_k","top_logprobs","top_p","try_from","try_from","try_from","try_into","try_into","try_into","type_id","type_id","type_id","vzip","vzip","vzip"],"q":[[0,"mistralrs_server"],[71,"mistralrs_server::ModelSelected"],[161,"mistralrs_server::openai"],[243,"clap_builder::builder::command"],[244,"mistralrs_core"],[245,"alloc::sync"],[246,"axum::extract::state"],[247,"axum::json"],[248,"alloc::string"],[249,"core::fmt"],[250,"core::fmt"],[251,"clap_builder"],[252,"core::result"],[253,"axum::routing"],[254,"clap_builder::util::id"],[255,"core::option"],[256,"anyhow"],[257,"core::any"],[258,"serde::de"],[259,"serde::ser"]],"d":["","Select the gemma model.","Select the llama model.","Select the quantized llama model with gguf.","Select the quantized llama model with gguf.","Select the mistral model.","Select the quantized mistral model with gguf.","Select the mixtral model.","Select the quantized mixtral model with gguf.","","Select the gemma model, with X-LoRA.","Select the llama model, with X-LoRA.","Select the quantized mistral model with gguf and X-LoRA.","Select the quantized mistral model with gguf and X-LoRA.","Select the mistral model, with X-LoRA.","Select the quantized mistral model with gguf and X-LoRA.","Select the mixtral model, with X-LoRA.","Select the quantized mistral model with gguf and X-LoRA.","","","","","","","","","JINJA chat template with <code>messages</code>, <code>add_generation_prompt</code>, …","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","","","","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Log all responses and requests to this file","","Maximum running sequences at any time. If the …","Model","Use no KV cache.","","Port to serve on.","IP to serve on. Defaults to “0.0.0.0”","If a sequence is larger than the maximum model length, …","","","","","","","","","","","","","GQA","GQA","Model ID to load from","Model ID to load from","Model ID to load from","Model ID to load from","Model ID to load from","Model ID to load from","Model ID to load from","Model ID to load from","Ordering JSON file","Ordering JSON file","Ordering JSON file","Ordering JSON file","Ordering JSON file","Ordering JSON file","Ordering JSON file","Ordering JSON file","Quantized filename, only applicable if <code>quantized</code> is set.","Quantized filename, only applicable if <code>quantized</code> is set.","Quantized filename, only applicable if <code>quantized</code> is set.","Quantized filename, only applicable if <code>quantized</code> is set.","Quantized filename, only applicable if <code>quantized</code> is set.","Quantized filename, only applicable if <code>quantized</code> is set.","Quantized filename, only applicable if <code>quantized</code> is set.","Quantized filename, only applicable if <code>quantized</code> is set.","Quantized model ID to find the <code>quantized_filename</code>, only …","Quantized model ID to find the <code>quantized_filename</code>, only …","Quantized model ID to find the <code>quantized_filename</code>, only …","Quantized model ID to find the <code>quantized_filename</code>, only …","Quantized model ID to find the <code>quantized_filename</code>, only …","Quantized model ID to find the <code>quantized_filename</code>, only …","Quantized model ID to find the <code>quantized_filename</code>, only …","Quantized model ID to find the <code>quantized_filename</code>, only …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Control the application of repeat penalty for the last n …","Index of completion tokens to generate scalings up until. …","Index of completion tokens to generate scalings up until. …","Index of completion tokens to generate scalings up until. …","Index of completion tokens to generate scalings up until. …","Index of completion tokens to generate scalings up until. …","Index of completion tokens to generate scalings up until. …","Index of completion tokens to generate scalings up until. …","Index of completion tokens to generate scalings up until. …","Model ID to load the tokenizer from","Model ID to load the tokenizer from","Model ID to load the tokenizer from","Model ID to load the tokenizer from","Model ID to load the tokenizer from","Model ID to load the tokenizer from","Model ID to load the tokenizer from","Model ID to load the tokenizer from","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Path to local tokenizer.json file. If this is specified it …","Model ID to load Xlora from","Model ID to load Xlora from","Model ID to load Xlora from","Model ID to load Xlora from","Model ID to load Xlora from","Model ID to load Xlora from","Model ID to load Xlora from","Model ID to load Xlora from","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""],"i":[0,10,10,10,10,10,10,10,10,0,10,10,10,10,10,10,10,10,16,16,10,10,10,16,10,16,16,0,16,16,10,16,10,16,10,16,10,10,16,10,16,10,16,0,16,10,10,16,10,16,16,0,16,16,16,0,16,16,16,10,16,10,16,10,16,10,16,10,16,10,16,28,29,30,31,32,33,34,35,36,37,31,33,35,37,38,39,29,40,41,42,28,43,38,39,29,40,41,42,28,43,38,39,29,40,30,41,31,32,33,34,42,28,35,36,43,37,38,39,29,40,31,33,35,37,38,39,29,40,41,42,28,43,38,39,29,40,30,41,31,32,33,34,42,28,35,36,43,37,38,39,29,40,31,33,35,37,38,39,29,40,0,0,25,25,25,25,0,24,25,5,24,25,5,24,25,5,24,25,5,24,0,0,24,25,5,24,25,5,24,25,5,24,25,5,24,25,5,24,25,5,24,25,5,24,25,5,24,25,5,5,5,5,5,5,5,24,5,5,24,24,25,5,5,5,24,25,5,5,5,5,24,25,5,24,25,5,24,25,5,24,25,5],"f":"``````````````````{bb}000{ce{}{}}000`{{{h{{f{d}}}}{l{j}}}n}{{}b}0{A`c{}}000{A`Ab}0{{AdAf}Ah}{cc{}}0{Aj{{An{AdAl}}}}{Aj{{An{B`Al}}}}10{{{f{d}}}Bb}{{}{{Bf{Bd}}}}{BhBj}{{}A`}0<<`{{}{{Bl{Ab}}}}```````{c{{An{e}}}{}{}}000{cBn{}}0{{AdAj}{{An{AbAl}}}}{{B`Aj}{{An{AbAl}}}}10{ce{}{}}0`````````````````````````````````````````````````````````````````````````````````````````````````000000{C`C`}{CbCb}{jj}{{ce}Ab{}{}}00`:{{}Bj}{A`c{}}00000{c{{An{C`}}}Cd}{c{{An{Cb}}}Cd}{c{{An{j}}}Cd}{A`Ab}00{{C`Af}Ah}{{CbAf}Ah}{{jAf}Ah}{cc{}}00000{{}A`}00???``````````{{C`c}AnCf}{{Cbc}AnCf}{{jc}AnCf}``{ce{}{}}00```{c{{An{e}}}{}{}}00000{cBn{}}00222","c":[],"p":[[5,"Command",243],[5,"MistralRs",244],[5,"Arc",245],[5,"State",246],[5,"ChatCompletionRequest",161],[5,"Json",247],[5,"String",248],[1,"usize"],[1,"unit"],[6,"ModelSelected",0],[5,"Formatter",249],[8,"Result",249],[5,"ArgMatches",250],[8,"Error",251],[6,"Result",252],[5,"Args",0],[5,"Router",253],[5,"Id",254],[6,"Option",255],[1,"str"],[1,"bool"],[8,"Result",256],[5,"TypeId",257],[5,"Message",161],[6,"StopTokens",161],[10,"Deserializer",258],[10,"Serializer",259],[15,"LlamaGGML",71],[15,"XLoraLlamaGGML",71],[15,"Mistral",71],[15,"XLoraMistral",71],[15,"Gemma",71],[15,"XLoraGemma",71],[15,"Llama",71],[15,"XLoraLlama",71],[15,"Mixtral",71],[15,"XLoraMixtral",71],[15,"XLoraMistralGGUF",71],[15,"XLoraLlamaGGUF",71],[15,"XLoraMixtralGGUF",71],[15,"MistralGGUF",71],[15,"LlamaGGUF",71],[15,"MixtralGGUF",71]],"b":[]}]\
]'));
if (typeof exports !== 'undefined') exports.searchIndex = searchIndex;
else if (window.initSearch) window.initSearch(searchIndex);
